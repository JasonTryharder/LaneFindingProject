{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some helper function image processing\n",
    "#  nice refreshing \n",
    "# https://stackoverflow.com/questions/49732726/how-to-compute-the-gradients-of-image-using-python\n",
    "# return image to gray scale \n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return gray\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return image info\n",
    "def imageInfo(img):\n",
    "    X_size = img.shape[1]\n",
    "    Y_size = img.shape[0]\n",
    "    print(\"image type is: \",type(img),\"\\n Xsize is: \",X_size,\"\\n Ysize is: \",Y_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return GaussianMasked image, square kernel\n",
    "def gaussianMask(img,kernel_size):\n",
    "    if kernel_size == 0 :\n",
    "        return img\n",
    "    # Define agaussianMask kernel size for Gaussian smoothing / blurring\n",
    "    # Note: this step is optional as cv2.Canny() applies a 5x5 Gaussian internally\n",
    "    masked = cv2.GaussianBlur(img,(kernel_size, kernel_size), 0)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion(image,erosion_size):\n",
    "    erosion_shape = cv2.MORPH_RECT\n",
    "    element = cv2.getStructuringElement(erosion_shape, (2 * erosion_size + 1, 2 * erosion_size + 1),(erosion_size, erosion_size))\n",
    "    erosion_dst = cv2.erode(image, element)\n",
    "    return erosion_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return colorMask color_threshold, easier for combined with other thresholds to do boolean operation\n",
    "def colorMask(img,threshold):\n",
    "# Define our color selection criteria\n",
    "# Note: if you run this code, you'll find these are not sensible values!!\n",
    "# But you'll get a chance to play with them soon in a quiz\n",
    "    red_threshold = threshold\n",
    "    green_threshold = threshold\n",
    "    blue_threshold = threshold\n",
    "    rgb_threshold = [red_threshold, green_threshold, blue_threshold]\n",
    "\n",
    "    # Do a boolean or with the \"|\" character to identify pixels below the thresholds\n",
    "    color_thresholds = (image[:,:,0] < rgb_threshold[0])|(image[:,:,1] < rgb_threshold[1])|(image[:,:,2] < rgb_threshold[2])\n",
    "    # color_select[thresholds] = [0,0,0]\n",
    "    # image[:,:,0] < rgb_threshold[0] will provide a boolean matrix with value smaller than threshold being true and larger being false\n",
    "    # when apply image[threshold_1,threshold_2,threshold_3] = 255 only true position will be replaced with the 255\n",
    "    # # Display the image                 \n",
    "    # plt.imshow(color_select)\n",
    "    # plt.show()\n",
    "    return color_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return RegionMask region_thresholds, easier for combined with other thresholds to do boolean operation\n",
    "def triangle_regionMask(img,edgeFactor,apexFactor):\n",
    "    # Define a triangle region of interest \n",
    "    # Keep in mind the origin (x=0, y=0) is in the upper left in image processing\n",
    "    ysize = img.shape[0]\n",
    "    xsize = img.shape[1]\n",
    "    left_bottom = [0, ysize*edgeFactor]\n",
    "    right_bottom = [xsize*edgeFactor, ysize*edgeFactor]\n",
    "    apex = [xsize*apexFactor, ysize*apexFactor]\n",
    "    \n",
    "    # Fit lines (y=Ax+B) to identify the  3 sided region of interest\n",
    "    # np.polyfit() returns the coefficients [A, B] of the fit\n",
    "    fit_left = np.polyfit((left_bottom[0], apex[0]), (left_bottom[1], apex[1]), 1)\n",
    "    fit_right = np.polyfit((right_bottom[0], apex[0]), (right_bottom[1], apex[1]), 1)\n",
    "    fit_bottom = np.polyfit((left_bottom[0], right_bottom[0]), (left_bottom[1], right_bottom[1]), 1)\n",
    "\n",
    "    # Find the region inside the lines\n",
    "    XX, YY = np.meshgrid(np.arange(0, xsize), np.arange(0, ysize))\n",
    "    region_thresholds = (YY > (XX*fit_left[0] + fit_left[1])) & \\\n",
    "                        (YY > (XX*fit_right[0] + fit_right[1])) & \\\n",
    "                        (YY < (XX*fit_bottom[0] + fit_bottom[1]))\n",
    "\n",
    "    # Color pixels black which are outside the region of interest\n",
    "#     img[~region_thresholds] = [0, 0, 0]\n",
    "    return region_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return RegionMask region_thresholds, easier for combined with other thresholds to do boolean operation\n",
    "def polygon_regionMask(edges,ratio, shift):\n",
    "    imshape = edges.shape\n",
    "    vertices = np.array([[(0,imshape[0]),(ratio*imshape[1]-shift, ratio*imshape[0]+shift), (ratio*imshape[1]+shift, ratio*imshape[0]+shift), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_edges = cv2.bitwise_and(edges,mask)\n",
    "    return masked_edges,vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some helper function computer vision\n",
    "# Canny requires gray image, threshold raion to be 1:2 or 1:3\n",
    "def canny(gray,low_threshold,high_threshold):\n",
    "    edges = cv2.Canny(gray,low_threshold,high_threshold) \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance from one point(P(x,y)) to a line(A(x,y),B(x,y)) \n",
    "# NOT USED\n",
    "def getDist_P2L(pointP,pointA,pointB):\n",
    "    A = pointA[1] - pointB[1]\n",
    "    B = pointA[0] - pointB[0]\n",
    "    C = pointA[0] * pointB[1] - pointA[1] * pointB[0]\n",
    "    distance = (np.abs(A*pointP[0] + B*pointP[1] + C))/(np.sqrt(A*A + B*B))\n",
    "    n = np.append(distance,10)\n",
    "    print(n)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get distance point to point\n",
    "def getDist_P2P(pointA,pointB):\n",
    "    pA_x = pointA[0]\n",
    "    pA_y = pointA[1]\n",
    "    pB_x = pointB[0]\n",
    "    pB_y = pointB[1]\n",
    "#     print(\"from getDist_P2P \", type(pA_x),pA_x, 10*pA_x)\n",
    "    return np.sqrt((pA_x-pB_x)*(pA_x-pB_x) + (pA_y-pB_y)*(pA_y-pB_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hough space point for a line in image space\n",
    "# to solve rho,t_idx, rho = diag_len + int(round(x * cos_t[t_idx] + y * sin_t[t_idx]))\n",
    "def getHough_Point(pointA_x,pointA_y,pointB_x,pointB_y):\n",
    "    tan_idx = -1*(pointA_x-pointB_x)/(pointA_y-pointB_y)\n",
    "    rad_idx = np.arctan(tan_idx)\n",
    "    diag_len = np.sqrt(540*540 + 960*960)\n",
    "    rho_idx = pointA_x*np.cos(rad_idx) + pointA_y*np.sin(rad_idx) + diag_len\n",
    "    x = rho_idx * np.cos(rad_idx)\n",
    "    y = rho_idx * np.sin(rad_idx)\n",
    "    return x,y\n",
    "#     return rad_idx, rho_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create distance matrix to help for merge lines \n",
    "def mergeLines(lines,threshold):\n",
    "#     distance_map stores distance b/t two lines distance in hough space\n",
    "    distance_map = np.zeros(shape = (len(lines),len(lines)))\n",
    "#     cluster_map stores the index of other line that below the threshold \n",
    "    cluster_map = np.zeros(shape = (len(lines),len(lines)))\n",
    "#     cluster_comparison stores the sum of all the points within threshold to the points\n",
    "    cluster_comparison = np.zeros(shape = (1,len(lines)))\n",
    "#     hough_P stores all hough points\n",
    "    houghP = np.zeros(shape = (len(lines),1,2))\n",
    "#     quality_ctr to make sure a line has decent amount of cluster\n",
    "    quality_ctr = 0\n",
    "    quality_ctr_limit = 3\n",
    "    loop_length = len(lines)\n",
    "    for i in range(loop_length):\n",
    "        if i >= loop_length:\n",
    "            break\n",
    "#         print(\"from MergeLines->i \",i, loop_length, type(i))\n",
    "        HoughP_A = getHough_Point(lines[i][:,0],lines[i][:,1],lines[i][:,2],lines[i][:,3])\n",
    "        houghP[i] = [getHough_Point(lines[i][:,0],lines[i][:,1],lines[i][:,2],lines[i][:,3])]\n",
    "        quality_ctr = 0\n",
    "        \n",
    "        for j in range (len(lines)):\n",
    "            HoughP_B = getHough_Point(lines[j][:,0],lines[j][:,1],lines[j][:,2],lines[j][:,3])\n",
    "            distance = getDist_P2P(HoughP_A, HoughP_B)\n",
    "            distance_map[i][j] = distance \n",
    "            if distance < threshold : \n",
    "                cluster_comparison[:,i] = cluster_comparison[:,i] + distance\n",
    "                cluster_map[i][j] = j\n",
    "                quality_ctr += 1\n",
    "        if (quality_ctr < quality_ctr_limit):\n",
    "#             if too small cluster than increate 1000 times to make it \n",
    "            i = i-1\n",
    "            cluster_comparison = np.delete(cluster_comparison,i,1)\n",
    "            distance_map = np.delete(distance_map,i,0)\n",
    "            cluster_map = np.delete(cluster_map,i,0)\n",
    "            houghP = np.delete(houghP,i,0)\n",
    "#             print(\"from MergeLInes after: \", cluster_comparison.shape, distance.shape, cluster_map.shape, houghP.shape)\n",
    "            loop_length -=1\n",
    "                \n",
    "    return distance_map, cluster_comparison, cluster_map, houghP        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort function will sort the array as assending order\n",
    "# implementing quick_sort mechanism\n",
    "def quick_sort(array):\n",
    "#     edge case 1 no/only 1 element\n",
    "    if len(array)<2:\n",
    "        return np.array(array)\n",
    "#     change array type to int by scale 1000 times and convert back after all finished\n",
    "\n",
    "#     Initialize place holder\n",
    "    pivot = array[-1]\n",
    "    total_len = len(array)\n",
    "    left = []\n",
    "    middle = []\n",
    "    right = []\n",
    "    left_index = []\n",
    "    middle_index = []\n",
    "    right_index = []\n",
    "    index_array = [*range(0,total_len)]# use * to unpack the array \n",
    "    counter = []\n",
    "    hist_right = 0\n",
    "    shift = 0\n",
    "\n",
    "#     main loop to accumulate \"array\"\n",
    "    while len(counter) < total_len:\n",
    "        for i in range(total_len):\n",
    "            if array[i] < pivot:\n",
    "                left = left +[array[i]]\n",
    "                left_index = left_index + [index_array[i]]\n",
    "            elif array[i] > pivot:\n",
    "                right = right + [array[i]]\n",
    "                right_index = right_index + [index_array[i]]\n",
    "            else:\n",
    "                middle = middle + [array[i]]\n",
    "                middle_index = middle_index + [index_array[i]]\n",
    "#     Assemble array for each pass             \n",
    "        array = left + middle + right\n",
    "        index_array = left_index + middle_index + right_index\n",
    "#     update shift and also check edge case 2 all element are same\n",
    "        if len(right) == hist_right and len(middle)!= total_len:\n",
    "            shift = len(middle) + len(right)\n",
    "#     update the counter only if when we need to update shift \n",
    "            counter= counter + middle\n",
    "#     adjust shift when the pivot is the smallest, hence no need to shift \n",
    "            if len(middle) + len(right) == total_len:\n",
    "                shift = shift - 1\n",
    "#     update pivot per shift, update hist_right and counter for last run\n",
    "        pivot = array[-1 - shift]\n",
    "        hist_right = len(right)\n",
    "#     clear left right middle place holder\n",
    "        left = []\n",
    "        right = []\n",
    "        middle = []\n",
    "        left_index = []\n",
    "        middle_index = []\n",
    "        right_index = []\n",
    "# return the sorted array and the orignal index referring to the input array\n",
    "# the index is used as a map to find the corresponding hough lines based on the sorted array \n",
    "    return np.array(array),np.array(index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare and check how many points overlaped between two arrays \n",
    "def compare_2_array(arrayA, arrayB):\n",
    "    counter = 0\n",
    "    for i in range(len(arrayA)):\n",
    "        for j in range(len(arrayB)):\n",
    "# if need to use arrayA[i].any() == arrayB[j].any() in any operands, that means the arrays in both side is not the same shape\n",
    "            if arrayA[i] != 0 and arrayA[i] == arrayB[j] :\n",
    "                counter +=1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hough Transform(line)\n",
    "def hough(masked_edges, rho, theta, threshold, min_line_length, max_line_gap):\n",
    "    # rho distance resolution in pixels in hough grid\n",
    "    theta = theta * np.pi/180   # angular resolution in radians of the Hough grid\n",
    "    # threshold minimum number of votes( intersection in hough grid)\n",
    "    # minimum number of pixels making up a line\n",
    "    # maximum gap in pixels between connectable line segments\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),\n",
    "                            min_line_length, max_line_gap)\n",
    "    original_houghLine = lines\n",
    "    # prepare color_edges by duplicate masked_edges    \n",
    "    color_edges = np.dstack((masked_edges,masked_edges,masked_edges))\n",
    "#     print(\"from hough-> color_edges type:\", type(color_edges[0][0][0]))\n",
    "    # creating a blank to draw lines on\n",
    "    line_image = np.copy(color_edges)*0 \n",
    "    mono_line = np.copy(masked_edges)*0\n",
    "#     print(line_image.shape)\n",
    "    [distance_map, cluster_comparison, cluster_map, houghPoint] = mergeLines(lines,500)\n",
    "    [sorted_cluster,cluster_index] = quick_sort(cluster_comparison[0])\n",
    "#     B = quick_sort(clusters_comparison[0])\n",
    "#     print(\"from hough -> compare quality ctr effect: \", lines.shape, distance_map.shape)\n",
    "#     print(\"from hough -> distance_map\\n\",distance_map)\n",
    "#     print(\"from hough -> cluster_map\\n\",cluster_map,cluster_map.shape)\n",
    "#     print(\"from hough -> cluster_comparison\\n\",cluster_comparison,cluster_comparison.shape)\n",
    "#     print(\"from hough -> sorted_cluster\\n\",sorted_cluster,sorted_cluster.shape)\n",
    "#     print(\"from hough -> sorted_cluster\\n\",cluster_index,cluster_index.shape)\n",
    "    final_index = []\n",
    "    unique_cluster = np.array([])\n",
    "    overlap_threshold = 3\n",
    "#     Note : clusters are sorted based on the distance from one point to rest point within threshold, did not threshold minimum number of points\n",
    "    for i in range(len(sorted_cluster)):\n",
    "        unique_signal = 0\n",
    "        j = 0\n",
    "        if i == 0:\n",
    "            final_index.append([cluster_index[i]])\n",
    "            unique_cluster = np.vstack([cluster_map[i,:]])\n",
    "#             print(\"in side hough comapre cluster loop: \\n\",cluster_index[i], cluster_map[i,:])\n",
    "        while j<len(final_index):\n",
    "            if compare_2_array(cluster_map[i,:],unique_cluster[j])>overlap_threshold:\n",
    "                unique_signal +=1\n",
    "            j+=1\n",
    "        if unique_signal == 0:\n",
    "            final_index.append([cluster_index[i]])\n",
    "            unique_cluster = np.vstack((unique_cluster, cluster_map[i,:]))\n",
    "#             print(\"in side hough comapre cluster loop: \\n\",cluster_index[i], cluster_map[i,:])\n",
    "\n",
    "    # Iterate over the output \"lines\" and draw lines on a blank image\n",
    "#     print(\"from hough-> final index/unique_cluster \\n\",final_index, unique_cluster)\n",
    "#     print(lines.shape,lines[0])\n",
    "    final_line = np.empty((len(final_index),1,4),dtype = np.int16)\n",
    "    for i in range(len(final_index)):\n",
    "        final_line[i] = lines[final_index[i]]\n",
    "#         print(\"from final_line loop\", final_index[i])\n",
    "#     print(\"from hough:\",houghPoint,final_line.shape,final_line)\n",
    "\n",
    "    #   plot some scatter of the hough points \n",
    "#     print(\"houghPoint plot\")\n",
    "#     fig0 = plt.figure(figsize = (10,7))\n",
    "#     fig,ax = plt.subplots()\n",
    "#     for i in houghPoint:\n",
    "#         ax.scatter(i[0][0],i[0][1])\n",
    "#     plt.imshow\n",
    "#     plt.title(\"hough space plot\")\n",
    "    \n",
    "    return final_line, original_houghLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  find top_left,bot_left,bot_right,top_right corner point from original_houghLine\n",
    "def find_corner_point(lines,width):\n",
    "#     assign some values to corner point\n",
    "#     left line AB, right line CD, from bottom left clock-wise A-B-C-D\n",
    "    left_x_A = lines[0][0][0]\n",
    "    left_y_A = lines[0][0][1]\n",
    "#     left_x_B, right_x_C need proper initial value\n",
    "    left_x_B = 0\n",
    "    left_y_B = 0\n",
    "    right_x_C = width\n",
    "    right_y_C = 0\n",
    "    right_x_D = lines[0][0][2]\n",
    "    right_y_D = lines[0][0][3]\n",
    "    for line in lines:\n",
    "        x1 = line[0][0]\n",
    "        y1 = line[0][1]\n",
    "        x2 = line[0][2]\n",
    "        y2 = line[0][3]\n",
    "#         print(\"from find_corner_point:\", x1,y1,x2,y2)\n",
    "        if x1 < width*0.5 and x2 < width*0.5:\n",
    "            if x1 < left_x_A:\n",
    "                left_x_A = x1\n",
    "                left_y_A = y1\n",
    "            if x2 > left_x_B:\n",
    "                left_x_B = x2\n",
    "                left_y_B = y2\n",
    "        if x1 > width*0.5 and x2 > width*0.5:\n",
    "            if x1 < right_x_C:\n",
    "                right_x_C = x1\n",
    "                right_y_C = y1\n",
    "            if x2 > right_x_D:\n",
    "                right_x_D = x2\n",
    "                right_y_D = y2\n",
    "    return [[left_x_A,left_y_A,left_x_B,left_y_B]],[[right_x_C,right_y_C,right_x_D,right_y_D]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_image(image,lines):\n",
    "#     convert image type to uint8\n",
    "    line_image = np.copy(image)*0 \n",
    "#     i = 0\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "#             print(x1,y1,x2,y2,\"x,y\",type(x1))\n",
    "            color = np.random.randint(0, 255, size=(3, ))\n",
    "#             print(\"from create_line_image:\",color)\n",
    "            cv2.line(line_image,(int(x1),int(y1)),(int(x2),int(y2)),(int(color[0]),int(color[1]),int(color[2])),10)\n",
    "#             if i%2==0:\n",
    "#                 cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "#             else :\n",
    "#                 cv2.line(line_image,(x1,y1),(x2,y2),(0,255,0),10)\n",
    "    return line_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the intersections between line and polygon and inside the polygon\n",
    "def find_intersection(polygon_vertices,lines):\n",
    "    Y_top = polygon_vertices[0][1][1]\n",
    "    Y_bot = polygon_vertices[0][3][1]\n",
    "    newline = []\n",
    "#     print(\"from find_intersection \",lines.shape,polygon_vertices.shape)\n",
    "    for i in range(len(lines)):\n",
    "        x1 = lines[i][0][0]\n",
    "        y1 = lines[i][0][1]\n",
    "        x2 = lines[i][0][2]\n",
    "        y2 = lines[i][0][3]\n",
    "        K = (y1-y2)/(x1-x2)\n",
    "        B = (x1*y2-y1*x2)/(x1-x2)\n",
    "#         if (K<0.001):\n",
    "#             K = 0.001\n",
    "        X_top = (Y_top-B)/K\n",
    "        X_bot = (Y_bot-B)/K\n",
    "        lines[i][0][0] = X_top\n",
    "        lines[i][0][1] = Y_top\n",
    "        lines[i][0][2] = X_bot\n",
    "        lines[i][0][3] = Y_bot\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a sanity check by check corner point against its moving average \n",
    "def mov_avg(hough_lines, avg):\n",
    "# hough_lines.shape = (2,1,4)\n",
    "# avg.shape = (2,3,1,4) (3 is can be changed )   \n",
    "    n = 0\n",
    "# threshold of 20% \n",
    "    threshold = 0.2\n",
    "    for i in range(2):\n",
    "        avg_xy = np.zeros(shape = (2,1,4))\n",
    "        n = 0\n",
    "        for j in range(len(avg[i])):\n",
    "            [x1,y1,x2,y2] = avg[i][j][0]\n",
    "            if x1 != 0:\n",
    "                n+=1\n",
    "                avg_xy[i] = avg_xy[i] + [x1,y1,x2,y2]\n",
    "        if n<=1:\n",
    "#             print(\"from mov_avg \",n)\n",
    "            pass\n",
    "        else: \n",
    "            \n",
    "            avg_xy[i] = avg_xy[i]/n\n",
    "            ax1 = avg_xy[i][0][0]\n",
    "            ay1 = avg_xy[i][0][1]\n",
    "            ax2 = avg_xy[i][0][2]\n",
    "            ay2 = avg_xy[i][0][3]\n",
    "            hough_lines[i][0][0] = ax1 if abs(ax1-hough_lines[i][0][0])/ax1 > threshold else hough_lines[i][0][0]\n",
    "            hough_lines[i][0][1] = ay1 if abs(ay1-hough_lines[i][0][1])/ay1 > threshold else hough_lines[i][0][1]\n",
    "            hough_lines[i][0][2] = ax2 if abs(ax2-hough_lines[i][0][2])/ax2 > threshold else hough_lines[i][0][2]\n",
    "            hough_lines[i][0][3] = ay2 if abs(ay2-hough_lines[i][0][3])/ay2 > threshold else hough_lines[i][0][3]\n",
    "#   update avg            \n",
    "        if n<3:\n",
    "#             no need to shift avg if not full \n",
    "            avg[i][n][0] = hough_lines[i][0]\n",
    "        else: \n",
    "#   shift avg \n",
    "            avg[i][0:2][0] = avg[i][1:3][0]\n",
    "            avg[i][2][0] = hough_lines[i][0]\n",
    "    return hough_lines, avg             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# program that contains the pipeline\n",
    "def process_image(image, hough_cluster_method, use_video):\n",
    "    # Basic computer vision techniques\n",
    "    global avg_line # setup global para to hold previous three frames \n",
    "    blur = gaussianMask(image,0)\n",
    "    erosion_image = erosion(blur,0)\n",
    "    gray = grayscale(erosion_image)\n",
    "    [ysize,xsize] = gray.shape\n",
    "    blur_gray = gaussianMask(gray,3)\n",
    "    edges = canny(blur_gray,150,300)\n",
    "    [masked_edges,polygon_vertices] = polygon_regionMask(edges,0.5,80)\n",
    "    [hough_lines,original_hough_lines] = hough(masked_edges,1,1,30,50,300)\n",
    "    if hough_cluster_method:\n",
    "#         hough_lines = find_intersection(polygon_vertices,hough_lines)\n",
    "        pass\n",
    "    else:\n",
    "        [ysize,xsize] = gray.shape\n",
    "        hough_lines = find_corner_point(original_hough_lines,xsize)\n",
    "        hough_lines = find_intersection(polygon_vertices,hough_lines)\n",
    "        [hough_lines, avg_line] = mov_avg(hough_lines,avg_line)\n",
    "#     print(\"from process_image \",hough_lines.shape)\n",
    "#     print(\"from process_image\",hough_lines.shape)\n",
    "    line_image = create_line_image(image,hough_lines)\n",
    "    combine_image = cv2.addWeighted(image,0.8,line_image,2,0)\n",
    "    if not use_video: \n",
    "        fig1 = plt.figure(figsize=(60,43))\n",
    "        fig1.add_subplot(6,1,1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"original image\")\n",
    "        fig1.add_subplot(6,1,2)\n",
    "        plt.imshow(blur_gray,cmap = \"Greys_r\")\n",
    "        plt.title(\"gray->blur image\")\n",
    "        fig1.add_subplot(6,1,3)\n",
    "        plt.imshow(masked_edges,cmap = \"Greys_r\")\n",
    "        plt.title(\"canny edge and masked with polygon region\")\n",
    "        fig1.add_subplot(6,1,4)\n",
    "        plt.imshow(combine_image)\n",
    "        plt.title(\"hough transform showing all image\")\n",
    "#         fig1.add_subplot(6,1,1)\n",
    "#         plt.imshow(masked_edges,cmap = \"Greys_r\")\n",
    "#         plt.title(\"with erosions\")\n",
    "#         fig1.add_subplot(6,1,2)\n",
    "#         plt.imshow(masked_edges,cmap = \"Greys_r\")\n",
    "#         plt.title(\"canny->polygon_masked\")\n",
    "#         fig2 = plt.figure(figsize=(10,7))\n",
    "#         plt.imshow(combine_image)\n",
    "#         plt.title(\"combined image\")\n",
    "#         plt.title(\"gray->blur->canny\"),plt.xticks([]), plt.yticks([])\n",
    "    return combine_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 9/222 [00:00<00:02, 85.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▊         | 19/222 [00:00<00:02, 88.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 28/222 [00:00<00:02, 88.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 38/222 [00:00<00:02, 91.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|██        | 47/222 [00:00<00:01, 87.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▍       | 55/222 [00:00<00:01, 84.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 63/222 [00:00<00:01, 80.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|███▏      | 71/222 [00:00<00:01, 78.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███▌      | 79/222 [00:00<00:01, 77.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|███▉      | 87/222 [00:01<00:01, 68.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▏     | 94/222 [00:01<00:01, 67.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████▌     | 101/222 [00:01<00:01, 68.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████▉     | 109/222 [00:01<00:01, 70.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████▎    | 117/222 [00:01<00:01, 63.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████▌    | 124/222 [00:01<00:01, 64.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████▉    | 132/222 [00:01<00:01, 67.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████▎   | 139/222 [00:01<00:01, 68.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████▌   | 147/222 [00:01<00:01, 70.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████▉   | 155/222 [00:02<00:00, 70.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████▎  | 163/222 [00:02<00:00, 64.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 170/222 [00:02<00:00, 64.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|███████▉  | 177/222 [00:02<00:00, 59.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 184/222 [00:02<00:00, 58.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████▋ | 193/222 [00:02<00:00, 63.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|█████████ | 201/222 [00:02<00:00, 66.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|█████████▍| 209/222 [00:02<00:00, 68.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 217/222 [00:03<00:00, 70.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|█████████▉| 221/222 [00:03<00:00, 71.10it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 6.7 s, sys: 270 ms, total: 6.97 s\n",
      "Wall time: 3.35 s\n",
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/682 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 5/682 [00:00<00:13, 48.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 15/682 [00:00<00:11, 57.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 26/682 [00:00<00:10, 65.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▍         | 32/682 [00:00<00:10, 62.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▌         | 40/682 [00:00<00:09, 66.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 47/682 [00:00<00:09, 65.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 55/682 [00:00<00:09, 67.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▉         | 63/682 [00:00<00:08, 70.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 71/682 [00:00<00:08, 73.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▏        | 79/682 [00:01<00:08, 72.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 87/682 [00:01<00:08, 68.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▍        | 94/682 [00:01<00:09, 60.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▍        | 101/682 [00:01<00:09, 59.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|█▌        | 109/682 [00:01<00:09, 62.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 116/682 [00:01<00:08, 63.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 124/682 [00:01<00:08, 67.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|█▉        | 133/682 [00:01<00:07, 71.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|██        | 141/682 [00:02<00:07, 71.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 150/682 [00:02<00:07, 74.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 158/682 [00:02<00:07, 74.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|██▍       | 166/682 [00:02<00:06, 75.28it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Basic image processing techniques\n",
    "#reading in an image \n",
    "# complication when using cv2.imread(), use BGR instead of RGB\n",
    "\n",
    "use_video = True\n",
    "use_hough_cluster = False\n",
    "# avg_line is the sanity check of the lines, currently using previous 3 frames\n",
    "avg_line = np.zeros(shape = (2,3,1,4),dtype = float)\n",
    "if (not use_video):\n",
    "    file = os.listdir(\"test_images/\")\n",
    "#     print(\"os function:\",np.array(file).shape,file)\n",
    "    for file_name in file:\n",
    "        file_name = 'test_images/' + file_name\n",
    "        image = mpimg.imread(file_name)\n",
    "        \n",
    "        process_image(image,use_hough_cluster,use_video)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "if (use_video):\n",
    "#     uncomment each block to test the result( challange_output is detection result error in some frames)\n",
    "    white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "    ## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "    ## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "    ## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "    ## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "    ##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "    clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "    white_clip = clip1.fl_image(lambda image: process_image(image,use_hough_cluster,use_video)) #NOTE: this function expects color images!!, use lambda function to add more argument\n",
    "    %time white_clip.write_videofile(white_output, audio=False)\n",
    "    \n",
    "    yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "    ## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "    ## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "    ## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "    ## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "    ##clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "    clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "    yellow_clip = clip2.fl_image(lambda image: process_image(image,use_hough_cluster,use_video))\n",
    "    %time yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "\n",
    "#     challenge_output = 'test_videos_output/challenge.mp4'\n",
    "#     ## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "#     ## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "#     ## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "#     ## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#     ##clip3 = VideoFileClip('test_videos/challenge.mp4').subclip(0,5)\n",
    "#     clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "#     challenge_clip = clip3.fl_image(lambda image: process_image(image,use_hough_cluster,use_video))\n",
    "#     %time challenge_clip.write_videofile(challenge_output, audio=False)\n",
    "\n",
    "\n",
    "# blur_gray = gaussianMask(gray,1)\n",
    "# edges = canny(blur_gray,150,300)\n",
    "# # print(type(edges), edges.shape, \"edges\", edges)\n",
    "# [masked_edges,polygon_vertices] = polygon_regionMask(edges,0.5,80)\n",
    "# hough_lines = hough(masked_edges,1,1,10,10,1)\n",
    "# hough_lines = find_intersection(polygon_vertices,hough_lines)\n",
    "# line_image = create_line_image(image,hough_lines)\n",
    "# # mono_line = hough(masked_edges,1,1,10,10,1)[1]\n",
    "# # second_hough_image = hough(mono_line,1,1,10,10,1)[0]\n",
    "# # print(mono_line.shape,edges.shape, \"shape\",type(mono_line), type(edges) )\n",
    "# # plt.imshow(mono_line,cmap = \"gray\")\n",
    "# # plt.imshow(second_hough_image)\n",
    "# combine_image = cv2.addWeighted(image,0.8,line_image,0.8,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
